{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cff46c-b3f5-4c5b-bb4e-2e290e4e6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import itertools\n",
    "from matplotlib.dates import DateFormatter\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ForexSentimentAnalysis:\n",
    "    def __init__(self, df1, df2, tag, debug_mode=False):\n",
    "        \"\"\"\n",
    "        Initialize the ForexSentimentAnalysis class.\n",
    "        \n",
    "        :param df1: DataFrame with sentiment scores\n",
    "        :param df2: DataFrame with forex prices\n",
    "        :param tag: Forex pair tag\n",
    "        \"\"\"\n",
    "        self.df1 = df1.copy()\n",
    "        self.df2 = df2.copy()\n",
    "        self.tag = tag\n",
    "        self.debug_mode = debug_mode\n",
    "        self.preprocess_data()\n",
    "        # Create results/records directory if it doesn't exist\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        if not os.path.exists('records'):\n",
    "            os.makedirs('records')\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the input dataframes.\"\"\"\n",
    "        # Convert datetime columns\n",
    "        self.df1['createDate'] = pd.to_datetime(self.df1['createDate'])\n",
    "        self.df2['asoftime'] = pd.to_datetime(self.df2['asoftime'], infer_datetime_format=True)\n",
    "\n",
    "        # Process df2\n",
    "        self.df2['mid'] = (self.df2['bid'] + self.df2['ask']) / 2\n",
    "        if self.tag.startswith('USD'):\n",
    "            for col in ['bid', 'ask', 'mid']:\n",
    "                self.df2[col] = 1 / self.df2[col]\n",
    "            self.df2['bid'], self.df2['ask'] = self.df2['ask'], self.df2['bid']\n",
    "\n",
    "    def resample_data(self, RT, model, window, keyword=''):\n",
    "        \"\"\"\n",
    "        Resample data based on given parameters.\n",
    "        \n",
    "        :param RT: Resample time period\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param keyword: Keyword for filtering df1\n",
    "        :return: Resampled and merged DataFrame\n",
    "        \"\"\"\n",
    "        # Filter df1 by keyword if provided\n",
    "        if keyword:\n",
    "            df1_filtered = self.df1[self.df1['keyword'] == keyword]\n",
    "        else:\n",
    "            df1_filtered = self.df1\n",
    "\n",
    "        # Resample df1\n",
    "        df11 = df1_filtered.resample(RT, on='createDate').agg({\n",
    "            f\"{model}_sentiment_title\": 'sum'\n",
    "        }).reset_index()\n",
    "        df11['time1'] = df11['createDate'].dt.floor('min')\n",
    "        ema_window = len(df11)//window\n",
    "        df11[f\"{model}_sentiment_title_{window}\"] = df11[f\"{model}_sentiment_title\"].ewm(span=ema_window, min_periods=len(df11)//5).mean()\n",
    "\n",
    "        # Resample df2\n",
    "        df21 = self.df2.resample(RT, on='asoftime').last().reset_index()\n",
    "        df21['time2'] = df21['asoftime'].dt.floor('min')\n",
    "\n",
    "        # Merge df11 and df21\n",
    "        df0 = pd.merge(df11, df21, left_on='time1', right_on='time2', how='outer')\n",
    "        df0['time'] = df0['time1'].combine_first(df0['time2'])\n",
    "        df0 = df0.sort_values('time')\n",
    "\n",
    "        return df0\n",
    "\n",
    "    def calculate_returns(self, df0, T):\n",
    "        \"\"\"\n",
    "        Calculate returns for different periods.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: DataFrame with calculated returns\n",
    "        \"\"\"\n",
    "        for t in T:\n",
    "            df0[f'R_{t}'] = df0['mid'].pct_change(t)\n",
    "        return df0\n",
    "\n",
    "    def calculate_correlation(self, df0, model, window, T):\n",
    "        \"\"\"\n",
    "        Calculate correlation between sentiment scores and returns.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: Dictionary of correlations\n",
    "        \"\"\"\n",
    "        correlations = {}\n",
    "        for t in T:\n",
    "            sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "            return_col = f'R_{t}'\n",
    "            \n",
    "            # Drop rows where either column has NaN values\n",
    "            valid_data = df0[[sentiment_col, return_col]].dropna()\n",
    "            \n",
    "            if len(valid_data) > 1:  # Ensure there's enough data to calculate correlation\n",
    "                corr, _ = stats.pearsonr(valid_data[sentiment_col], valid_data[return_col])\n",
    "                correlations[t] = corr\n",
    "            else:\n",
    "                correlations[t] = np.nan\n",
    "        return correlations\n",
    "\n",
    "    def process_combination(self, params):\n",
    "        \"\"\"\n",
    "        Process a single parameter combination.\n",
    "        \n",
    "        :param params: Tuple of (RT, model, window, keyword, T_list, train_end_date)\n",
    "        :return: List of results for this combination\n",
    "        \"\"\"\n",
    "        RT, model, window, keyword, T_list, train_end_date = params\n",
    "        df0_file = f\"records/{self.tag}_{RT}_{model}_{window}_{keyword}.csv\"\n",
    "\n",
    "        if os.path.exists(df0_file):\n",
    "            df0 = pd.read_csv(df0_file, parse_dates=['time'])\n",
    "        else:\n",
    "            df0 = self.resample_data(RT, model, window, keyword)\n",
    "            df0.to_csv(df0_file, index=False)\n",
    "\n",
    "        df0 = self.calculate_returns(df0, T_list)\n",
    "\n",
    "        train_df0 = df0[df0['time'] <= train_end_date]\n",
    "        test_df0 = df0[df0['time'] > train_end_date]\n",
    "\n",
    "        train_corr = self.calculate_correlation(train_df0, model, window, T_list)\n",
    "        test_corr = self.calculate_correlation(test_df0, model, window, T_list)\n",
    "\n",
    "        return [(RT, model, window, keyword, t, train_corr[t], test_corr[t]) for t in T_list]\n",
    "\n",
    "    def optimize_parameters(self, RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=None):\n",
    "        \"\"\"\n",
    "        Optimize parameters using grid search and parallel or serial processing.\n",
    "        \n",
    "        :param RT_list: List of resample time periods\n",
    "        :param model_list: List of model names\n",
    "        :param T_list: List of periods for return calculation\n",
    "        :param window_list: List of EMA window sizes\n",
    "        :param keyword_list: List of keywords for filtering\n",
    "        :param train_end_date: End date for the training set\n",
    "        :param n: Number of top results to display (optional)\n",
    "        :return: DataFrame with optimization results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        param_combinations = list(itertools.product(RT_list, model_list, window_list, keyword_list))\n",
    "        param_combinations = [(RT, model, window, keyword, T_list, train_end_date) for RT, model, window, keyword in param_combinations]\n",
    "\n",
    "        if self.debug_mode:\n",
    "            for params in param_combinations:\n",
    "                result = self.process_combination(params)\n",
    "                results.extend(result)\n",
    "        else:\n",
    "            with ProcessPoolExecutor() as executor:\n",
    "                for result in executor.map(self.process_combination, param_combinations):\n",
    "                    results.extend(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results, columns=['RT', 'model', 'window', 'keyword', 'T', 'train_corr', 'test_corr'])\n",
    "        results_df = results_df.sort_values('train_corr', key=abs, ascending=False)\n",
    "\n",
    "        # Save all results to Excel\n",
    "        results_df.to_excel(f'results/{self.tag}_all_results.xlsx', index=False)\n",
    "\n",
    "        if n:\n",
    "            results_df = results_df.head(n).reset_index(drop=True)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def plot_top_correlations(self, results_df, n=5, train_end_date=None):\n",
    "        \"\"\"\n",
    "        Plot top n correlations and time series for the best configuration.\n",
    "        \n",
    "        :param results_df: DataFrame with optimization results\n",
    "        :param n: Number of top results to plot\n",
    "        :param train_end_date: End date for the training set\n",
    "        \"\"\"\n",
    "        top_n = results_df.head(n)\n",
    "        \n",
    "        # Plot correlations\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        x = range(len(top_n))\n",
    "        labels = [f\"{row.RT}_{row.model}_{row.window}_{row['T']}\" for _, row in top_n.iterrows()]\n",
    "        \n",
    "        width = 0.35\n",
    "        ax.bar([i - width/2 for i in x], top_n['train_corr'], width, label='Train', alpha=0.8)\n",
    "        ax.bar([i + width/2 for i in x], top_n['test_corr'], width, label='Test', alpha=0.8)\n",
    "        \n",
    "        ax.set_title(f'Top {n} Correlations (Train vs Test)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Correlation')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # plt.show()\n",
    "        plt.savefig(f'results/{self.tag}_top_correlations.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot time series for the best configuration\n",
    "        best_config = top_n.iloc[0]\n",
    "        RT, model, window, keyword, T = best_config[['RT', 'model', 'window', 'keyword', 'T']]\n",
    "        \n",
    "        df0_file = f\"records/{self.tag}_{RT}_{model}_{window}_{keyword}.csv\"\n",
    "        if os.path.exists(df0_file):\n",
    "            df0 = pd.read_csv(df0_file, parse_dates=['time'])\n",
    "        else:\n",
    "            df0 = self.resample_data(RT, model, window, keyword)\n",
    "            df0 = self.calculate_returns(df0, [T])\n",
    "        \n",
    "        sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "        \n",
    "        df_plot = df0.dropna(subset=[sentiment_col, 'mid'])\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        train_mask = df_plot['time'] <= train_end_date\n",
    "        ax1.plot(df_plot[train_mask]['time'], df_plot[train_mask][sentiment_col], color='blue', label=f'{sentiment_col} (Train)')\n",
    "        ax1.plot(df_plot[~train_mask]['time'], df_plot[~train_mask][sentiment_col], color='blue', linestyle='--', label=f'{sentiment_col} (Test)')\n",
    "        \n",
    "        ax2.plot(df_plot[train_mask]['time'], df_plot[train_mask]['mid'], color='red', label='Mid Price (Train)')\n",
    "        ax2.plot(df_plot[~train_mask]['time'], df_plot[~train_mask]['mid'], color='red', linestyle='--', label='Mid Price (Test)')\n",
    "        \n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel(sentiment_col, color='blue')\n",
    "        ax2.set_ylabel('Mid Price', color='red')\n",
    "        \n",
    "        y1_min, y1_max = df_plot[sentiment_col].min(), df_plot[sentiment_col].max()\n",
    "        y2_min, y2_max = df_plot['mid'].min(), df_plot['mid'].max()\n",
    "        \n",
    "        y1_range = y1_max - y1_min\n",
    "        y2_range = y2_max - y2_min\n",
    "        \n",
    "        ax1.set_ylim(y1_min - 0.1*y1_range, y1_max + 0.1*y1_range)\n",
    "        ax2.set_ylim(y2_min - 0.1*y2_range, y2_max + 0.1*y2_range)\n",
    "        \n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        # Calculate correlations for train and test sets\n",
    "        train_corr = df_plot[train_mask][[sentiment_col, 'mid']].corr().iloc[0, 1]\n",
    "        test_corr = df_plot[~train_mask][[sentiment_col, 'mid']].corr().iloc[0, 1]\n",
    "        \n",
    "        plt.title(f'Sentiment vs Mid Price for {self.tag}\\n{sentiment_col}, RT={RT}, T={T}\\n'\n",
    "                  f'Train Corr: {train_corr:.4f}, Test Corr: {test_corr:.4f}')\n",
    "        \n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        ax1.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n",
    "        fig.autofmt_xdate()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # plt.savefig(f'results/{self.tag}_best_config_time_series.png')\n",
    "        # plt.close()\n",
    "\n",
    "# Test example\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    tag = 'USDCNH'\n",
    "    tag_short = tag.replace('USD','')\n",
    "    debug = True\n",
    "    df1 = pd.read_csv(f'data/{tag}_news_scores.csv')\n",
    "    df1 = df1.rename(columns={f'ABSA_Bert_sentiment_title_{tag_short}':'ABSA_sentiment_title'})\n",
    "\n",
    "    df2 = pd.read_csv(f'data/{tag}.csv')\n",
    "\n",
    "    # Initialize the ForexSentimentAnalysis class with debug_mode=True for debugging\n",
    "    fsa = ForexSentimentAnalysis(df1, df2, tag=tag, debug_mode=debug)\n",
    "\n",
    "    # Define parameters for optimization\n",
    "    RT_list = ['15min', '10min', '30min']\n",
    "    model_list = ['Vader', 'ABSA', 'FinBERT']\n",
    "    T_list = [1, 5, 10, 15, 30, 60, 120]\n",
    "    window_list = [20]\n",
    "    keyword_list = ['']\n",
    "    train_end_date = '2024-04-30'\n",
    "\n",
    "    # Run optimization\n",
    "    results = fsa.optimize_parameters(RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=10)\n",
    "\n",
    "    # Print results\n",
    "    print(results)\n",
    "\n",
    "    # Plot top correlations and time series\n",
    "    fsa.plot_top_correlations(results, n=10, train_end_date=pd.to_datetime(train_end_date))\n",
    "    print(f'Total running time: {time.time()-start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b87358-fcc4-4863-81a8-ade3513f4c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
