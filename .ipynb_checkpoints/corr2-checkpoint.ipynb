{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d6c27-4b30-4129-982c-3cbccc7c6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "class ForexSentimentAnalysis:\n",
    "    def __init__(self, df1, df2, tag):\n",
    "        \"\"\"\n",
    "        Initialize the ForexSentimentAnalysis class.\n",
    "        \n",
    "        :param df1: DataFrame with sentiment scores\n",
    "        :param df2: DataFrame with forex prices\n",
    "        :param tag: Forex pair tag\n",
    "        \"\"\"\n",
    "        self.df1 = df1.copy()\n",
    "        self.df2 = df2.copy()\n",
    "        self.tag = tag\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the input dataframes.\"\"\"\n",
    "        # Convert datetime columns\n",
    "        self.df1['createDate'] = pd.to_datetime(self.df1['createDate'])\n",
    "        self.df2['asoftime'] = pd.to_datetime(self.df2['asoftime'])\n",
    "\n",
    "        # Process df2\n",
    "        self.df2['mid'] = (self.df2['bid'] + self.df2['ask']) / 2\n",
    "        if self.tag.startswith('USD'):\n",
    "            for col in ['bid', 'ask', 'mid']:\n",
    "                self.df2[col] = 1 / self.df2[col]\n",
    "            self.df2['bid'], self.df2['ask'] = self.df2['ask'], self.df2['bid']\n",
    "\n",
    "    def resample_data(self, RT, model, window, keyword=''):\n",
    "        \"\"\"\n",
    "        Resample data based on given parameters.\n",
    "        \n",
    "        :param RT: Resample time period\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param keyword: Keyword for filtering df1\n",
    "        :return: Resampled and merged DataFrame\n",
    "        \"\"\"\n",
    "        # Filter df1 by keyword if provided\n",
    "        if keyword:\n",
    "            df1_filtered = self.df1[self.df1['keyword'] == keyword]\n",
    "        else:\n",
    "            df1_filtered = self.df1\n",
    "\n",
    "        # Resample df1\n",
    "        df11 = df1_filtered.resample(RT, on='createDate').agg({\n",
    "            f\"{model}_sentiment_title\": 'sum'\n",
    "        }).reset_index()\n",
    "        df11['time1'] = df11['createDate'].dt.floor('min')\n",
    "        df11[f\"{model}_sentiment_title_{window}\"] = df11[f\"{model}_sentiment_title\"].ewm(span=window).mean()\n",
    "\n",
    "        # Resample df2\n",
    "        df21 = self.df2.resample(RT, on='asoftime').last().reset_index()\n",
    "        df21['time2'] = df21['asoftime'].dt.floor('min')\n",
    "\n",
    "        # Merge df11 and df21\n",
    "        df0 = pd.merge(df11, df21, left_on='time1', right_on='time2', how='outer')\n",
    "        df0['time'] = df0['time1'].combine_first(df0['time2'])\n",
    "        df0 = df0.sort_values('time')\n",
    "\n",
    "        return df0\n",
    "\n",
    "    def calculate_returns(self, df0, T):\n",
    "        \"\"\"\n",
    "        Calculate returns for different periods.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: DataFrame with calculated returns\n",
    "        \"\"\"\n",
    "        for t in T:\n",
    "            df0[f'R_{t}'] = df0['mid'].pct_change(t)\n",
    "        return df0\n",
    "\n",
    "    def calculate_correlation(self, df0, model, window, T):\n",
    "        \"\"\"\n",
    "        Calculate correlation between sentiment scores and returns.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: Dictionary of correlations\n",
    "        \"\"\"\n",
    "        correlations = {}\n",
    "        for t in T:\n",
    "            sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "            return_col = f'R_{t}'\n",
    "            \n",
    "            # Drop rows where either column has NaN values\n",
    "            valid_data = df0[[sentiment_col, return_col]].dropna()\n",
    "            \n",
    "            if len(valid_data) > 1:  # Ensure there's enough data to calculate correlation\n",
    "                corr, _ = stats.pearsonr(valid_data[sentiment_col], valid_data[return_col])\n",
    "                correlations[t] = corr\n",
    "            else:\n",
    "                correlations[t] = np.nan\n",
    "        return correlations\n",
    "\n",
    "    def optimize_parameters(self, RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=None):\n",
    "        \"\"\"\n",
    "        Optimize parameters using grid search and parallel processing.\n",
    "        \n",
    "        :param RT_list: List of resample time periods\n",
    "        :param model_list: List of model names\n",
    "        :param T_list: List of periods for return calculation\n",
    "        :param window_list: List of EMA window sizes\n",
    "        :param keyword_list: List of keywords for filtering\n",
    "        :param train_end_date: End date for the training set\n",
    "        :param n: Number of top results to display (optional)\n",
    "        :return: DataFrame with optimization results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        param_combinations = list(itertools.product(RT_list, model_list, window_list, keyword_list))\n",
    "\n",
    "        def process_combination(params):\n",
    "            RT, model, window, keyword = params\n",
    "            df0_file = f\"records/{self.tag}_{RT}_{model}_{window}_{keyword}.csv\"\n",
    "\n",
    "            if os.path.exists(df0_file):\n",
    "                df0 = pd.read_csv(df0_file, parse_dates=['time'])\n",
    "            else:\n",
    "                df0 = self.resample_data(RT, model, window, keyword)\n",
    "                df0.to_csv(df0_file, index=False)\n",
    "\n",
    "            df0 = self.calculate_returns(df0, T_list)\n",
    "\n",
    "            train_df0 = df0[df0['time'] <= train_end_date]\n",
    "            test_df0 = df0[df0['time'] > train_end_date]\n",
    "\n",
    "            train_corr = self.calculate_correlation(train_df0, model, window, T_list)\n",
    "            test_corr = self.calculate_correlation(test_df0, model, window, T_list)\n",
    "\n",
    "            return [(RT, model, window, keyword, t, train_corr[t], test_corr[t]) for t in T_list]\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            for result in executor.map(process_combination, param_combinations):\n",
    "                results.extend(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results, columns=['RT', 'model', 'window', 'keyword', 'T', 'train_corr', 'test_corr'])\n",
    "        results_df = results_df.sort_values('train_corr', key=abs, ascending=False)\n",
    "\n",
    "        if n:\n",
    "            results_df = results_df.head(n)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def plot_top_correlations(self, results_df, n=5):\n",
    "        \"\"\"\n",
    "        Plot top n correlations.\n",
    "        \n",
    "        :param results_df: DataFrame with optimization results\n",
    "        :param n: Number of top results to plot\n",
    "        \"\"\"\n",
    "        top_n = results_df.head(n)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        x = range(len(top_n))\n",
    "        labels = [f\"{row.model}_{row.window}_{row.T}\" for _, row in top_n.iterrows()]\n",
    "        \n",
    "        ax1.bar(x, top_n['train_corr'], label='Train')\n",
    "        ax1.set_title(f'Top {n} Correlations (Train)')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax1.set_ylabel('Correlation')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.bar(x, top_n['test_corr'], label='Test')\n",
    "        ax2.set_title(f'Top {n} Correlations (Test)')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax2.set_ylabel('Correlation')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data\n",
    "    df1 = pd.DataFrame({\n",
    "        'createDate': pd.date_range(start='2023-01-01', end='2023-12-31', freq='H'),\n",
    "        'model1_sentiment_title': np.random.uniform(-1, 1, 8760),\n",
    "        'model2_sentiment_title': np.random.uniform(-1, 1, 8760),\n",
    "        'keyword': np.random.choice(['A', 'B', 'C'], 8760)\n",
    "    })\n",
    "\n",
    "    df2 = pd.DataFrame({\n",
    "        'asoftime': pd.date_range(start='2023-01-01', end='2023-12-31', freq='10min'),\n",
    "        'bid': np.random.uniform(1.0, 1.5, 52560),\n",
    "        'ask': np.random.uniform(1.0, 1.5, 52560)\n",
    "    })\n",
    "\n",
    "    # Initialize the ForexSentimentAnalysis class\n",
    "    fsa = ForexSentimentAnalysis(df1, df2, tag='EURUSD')\n",
    "\n",
    "    # Define parameters for optimization\n",
    "    RT_list = ['1H', '4H', '1D']\n",
    "    model_list = ['model1', 'model2']\n",
    "    T_list = [1, 3, 5]\n",
    "    window_list = [12, 24, 48]\n",
    "    keyword_list = ['', 'A', 'B', 'C']\n",
    "    train_end_date = '2023-11-30'\n",
    "\n",
    "    # Run optimization\n",
    "    results = fsa.optimize_parameters(RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=10)\n",
    "\n",
    "    # Print results\n",
    "    print(results)\n",
    "\n",
    "    # Plot top correlations\n",
    "    fsa.plot_top_correlations(results, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f6805-9b84-4efd-83c3-0919f53d2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "class ForexSentimentAnalysis:\n",
    "    def __init__(self, df1, df2, tag):\n",
    "        \"\"\"\n",
    "        Initialize the ForexSentimentAnalysis class.\n",
    "        \n",
    "        :param df1: DataFrame with sentiment scores\n",
    "        :param df2: DataFrame with forex prices\n",
    "        :param tag: Forex pair tag\n",
    "        \"\"\"\n",
    "        self.df1 = df1.copy()\n",
    "        self.df2 = df2.copy()\n",
    "        self.tag = tag\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the input dataframes.\"\"\"\n",
    "        # Convert datetime columns\n",
    "        self.df1['createDate'] = pd.to_datetime(self.df1['createDate'])\n",
    "        self.df2['asoftime'] = pd.to_datetime(self.df2['asoftime'])\n",
    "\n",
    "        # Process df2\n",
    "        self.df2['mid'] = (self.df2['bid'] + self.df2['ask']) / 2\n",
    "        if self.tag.startswith('USD'):\n",
    "            for col in ['bid', 'ask', 'mid']:\n",
    "                self.df2[col] = 1 / self.df2[col]\n",
    "            self.df2['bid'], self.df2['ask'] = self.df2['ask'], self.df2['bid']\n",
    "\n",
    "    def resample_data(self, RT, model, window, keyword=''):\n",
    "        \"\"\"\n",
    "        Resample data based on given parameters.\n",
    "        \n",
    "        :param RT: Resample time period\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param keyword: Keyword for filtering df1\n",
    "        :return: Resampled and merged DataFrame\n",
    "        \"\"\"\n",
    "        # Filter df1 by keyword if provided\n",
    "        if keyword:\n",
    "            df1_filtered = self.df1[self.df1['keyword'] == keyword]\n",
    "        else:\n",
    "            df1_filtered = self.df1\n",
    "\n",
    "        # Resample df1\n",
    "        df11 = df1_filtered.resample(RT, on='createDate').agg({\n",
    "            f\"{model}_sentiment_title\": 'sum'\n",
    "        }).reset_index()\n",
    "        df11['time1'] = df11['createDate'].dt.floor('min')\n",
    "        df11[f\"{model}_sentiment_title_{window}\"] = df11[f\"{model}_sentiment_title\"].ewm(span=window).mean()\n",
    "\n",
    "        # Resample df2\n",
    "        df21 = self.df2.resample(RT, on='asoftime').last().reset_index()\n",
    "        df21['time2'] = df21['asoftime'].dt.floor('min')\n",
    "\n",
    "        # Merge df11 and df21\n",
    "        df0 = pd.merge(df11, df21, left_on='time1', right_on='time2', how='outer')\n",
    "        df0['time'] = df0['time1'].combine_first(df0['time2'])\n",
    "        df0 = df0.sort_values('time')\n",
    "\n",
    "        return df0\n",
    "\n",
    "    def calculate_returns(self, df0, T):\n",
    "        \"\"\"\n",
    "        Calculate returns for different periods.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: DataFrame with calculated returns\n",
    "        \"\"\"\n",
    "        for t in T:\n",
    "            df0[f'R_{t}'] = df0['mid'].pct_change(t)\n",
    "        return df0\n",
    "\n",
    "    def calculate_correlation(self, df0, model, window, T):\n",
    "        \"\"\"\n",
    "        Calculate correlation between sentiment scores and returns.\n",
    "        \n",
    "        :param df0: Input DataFrame\n",
    "        :param model: Model name\n",
    "        :param window: EMA window size\n",
    "        :param T: List of periods for return calculation\n",
    "        :return: Dictionary of correlations\n",
    "        \"\"\"\n",
    "        correlations = {}\n",
    "        for t in T:\n",
    "            sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "            return_col = f'R_{t}'\n",
    "            \n",
    "            # Drop rows where either column has NaN values\n",
    "            valid_data = df0[[sentiment_col, return_col]].dropna()\n",
    "            \n",
    "            if len(valid_data) > 1:  # Ensure there's enough data to calculate correlation\n",
    "                corr, _ = stats.pearsonr(valid_data[sentiment_col], valid_data[return_col])\n",
    "                correlations[t] = corr\n",
    "            else:\n",
    "                correlations[t] = np.nan\n",
    "        return correlations\n",
    "\n",
    "    def process_combination(self, params):\n",
    "        \"\"\"\n",
    "        Process a single parameter combination.\n",
    "        \n",
    "        :param params: Tuple of (RT, model, window, keyword, T_list, train_end_date)\n",
    "        :return: List of results for this combination\n",
    "        \"\"\"\n",
    "        RT, model, window, keyword, T_list, train_end_date = params\n",
    "        df0_file = f\"records/{self.tag}_{RT}_{model}_{window}_{keyword}.csv\"\n",
    "\n",
    "        if os.path.exists(df0_file):\n",
    "            df0 = pd.read_csv(df0_file, parse_dates=['time'])\n",
    "        else:\n",
    "            df0 = self.resample_data(RT, model, window, keyword)\n",
    "            df0.to_csv(df0_file, index=False)\n",
    "\n",
    "        df0 = self.calculate_returns(df0, T_list)\n",
    "\n",
    "        train_df0 = df0[df0['time'] <= train_end_date]\n",
    "        test_df0 = df0[df0['time'] > train_end_date]\n",
    "\n",
    "        train_corr = self.calculate_correlation(train_df0, model, window, T_list)\n",
    "        test_corr = self.calculate_correlation(test_df0, model, window, T_list)\n",
    "\n",
    "        return [(RT, model, window, keyword, t, train_corr[t], test_corr[t]) for t in T_list]\n",
    "\n",
    "    def optimize_parameters(self, RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=None):\n",
    "        \"\"\"\n",
    "        Optimize parameters using grid search and parallel processing.\n",
    "        \n",
    "        :param RT_list: List of resample time periods\n",
    "        :param model_list: List of model names\n",
    "        :param T_list: List of periods for return calculation\n",
    "        :param window_list: List of EMA window sizes\n",
    "        :param keyword_list: List of keywords for filtering\n",
    "        :param train_end_date: End date for the training set\n",
    "        :param n: Number of top results to display (optional)\n",
    "        :return: DataFrame with optimization results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        param_combinations = list(itertools.product(RT_list, model_list, window_list, keyword_list))\n",
    "        param_combinations = [(RT, model, window, keyword, T_list, train_end_date) for RT, model, window, keyword in param_combinations]\n",
    "\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            for result in executor.map(self.process_combination, param_combinations):\n",
    "                results.extend(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results, columns=['RT', 'model', 'window', 'keyword', 'T', 'train_corr', 'test_corr'])\n",
    "        results_df = results_df.sort_values('train_corr', key=abs, ascending=False)\n",
    "\n",
    "        if n:\n",
    "            results_df = results_df.head(n)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def plot_top_correlations(self, results_df, n=5):\n",
    "        \"\"\"\n",
    "        Plot top n correlations.\n",
    "        \n",
    "        :param results_df: DataFrame with optimization results\n",
    "        :param n: Number of top results to plot\n",
    "        \"\"\"\n",
    "        top_n = results_df.head(n)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        x = range(len(top_n))\n",
    "        labels = [f\"{row.model}_{row.window}_{row.T}\" for _, row in top_n.iterrows()]\n",
    "        \n",
    "        ax1.bar(x, top_n['train_corr'], label='Train')\n",
    "        ax1.set_title(f'Top {n} Correlations (Train)')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax1.set_ylabel('Correlation')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.bar(x, top_n['test_corr'], label='Test')\n",
    "        ax2.set_title(f'Top {n} Correlations (Test)')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax2.set_ylabel('Correlation')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data\n",
    "    df1 = pd.DataFrame({\n",
    "        'createDate': pd.date_range(start='2023-01-01', end='2023-12-31', freq='H'),\n",
    "        'model1_sentiment_title': np.random.uniform(-1, 1, 8760),\n",
    "        'model2_sentiment_title': np.random.uniform(-1, 1, 8760),\n",
    "        'keyword': np.random.choice(['A', 'B', 'C'], 8760)\n",
    "    })\n",
    "\n",
    "    df2 = pd.DataFrame({\n",
    "        'asoftime': pd.date_range(start='2023-01-01', end='2023-12-31', freq='10min'),\n",
    "        'bid': np.random.uniform(1.0, 1.5, 52560),\n",
    "        'ask': np.random.uniform(1.0, 1.5, 52560)\n",
    "    })\n",
    "\n",
    "    # Initialize the ForexSentimentAnalysis class\n",
    "    fsa = ForexSentimentAnalysis(df1, df2, tag='EURUSD')\n",
    "\n",
    "    # Define parameters for optimization\n",
    "    RT_list = ['1H', '4H', '1D']\n",
    "    model_list = ['model1', 'model2']\n",
    "    T_list = [1, 3, 5]\n",
    "    window_list = [12, 24, 48]\n",
    "    keyword_list = ['', 'A', 'B', 'C']\n",
    "    train_end_date = '2023-11-30'\n",
    "\n",
    "    # Run optimization\n",
    "    results = fsa.optimize_parameters(RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=10)\n",
    "\n",
    "    # Print results\n",
    "    print(results)\n",
    "\n",
    "    # Plot top correlations\n",
    "    fsa.plot_top_correlations(results, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cff46c-b3f5-4c5b-bb4e-2e290e4e6c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd2227-fe91-4d13-b5ce-0713860344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import itertools\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "class ForexSentimentAnalysis:\n",
    "    # ... (previous methods remain unchanged)\n",
    "\n",
    "    def plot_top_correlations(self, results_df, n=5, train_end_date=None):\n",
    "        \"\"\"\n",
    "        Plot top n correlations and time series for the best configuration.\n",
    "        \n",
    "        :param results_df: DataFrame with optimization results\n",
    "        :param n: Number of top results to plot\n",
    "        :param train_end_date: End date for the training set\n",
    "        \"\"\"\n",
    "        top_n = results_df.head(n)\n",
    "        \n",
    "        # Plot correlations\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        x = range(len(top_n))\n",
    "        labels = [f\"{row.model}_{row.window}_{row.T}\" for _, row in top_n.iterrows()]\n",
    "        \n",
    "        width = 0.35\n",
    "        ax.bar([i - width/2 for i in x], top_n['train_corr'], width, label='Train', alpha=0.8)\n",
    "        ax.bar([i + width/2 for i in x], top_n['test_corr'], width, label='Test', alpha=0.8)\n",
    "        \n",
    "        ax.set_title(f'Top {n} Correlations (Train vs Test)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax.set_ylabel('Correlation')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot time series for the best configuration\n",
    "        best_config = top_n.iloc[0]\n",
    "        RT, model, window, keyword, T = best_config[['RT', 'model', 'window', 'keyword', 'T']]\n",
    "        \n",
    "        df0_file = f\"records/{self.tag}_{RT}_{model}_{window}_{keyword}.csv\"\n",
    "        if os.path.exists(df0_file):\n",
    "            df0 = pd.read_csv(df0_file, parse_dates=['time'])\n",
    "        else:\n",
    "            df0 = self.resample_data(RT, model, window, keyword)\n",
    "            df0 = self.calculate_returns(df0, [T])\n",
    "        \n",
    "        sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "        \n",
    "        # Filter out rows where either sentiment or mid is NaN\n",
    "        df_plot = df0.dropna(subset=[sentiment_col, 'mid'])\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        # Plot sentiment\n",
    "        train_mask = df_plot['time'] <= train_end_date\n",
    "        ax1.plot(df_plot[train_mask]['time'], df_plot[train_mask][sentiment_col], color='blue', label=f'{sentiment_col} (Train)')\n",
    "        ax1.plot(df_plot[~train_mask]['time'], df_plot[~train_mask][sentiment_col], color='blue', linestyle='--', label=f'{sentiment_col} (Test)')\n",
    "        \n",
    "        # Plot mid price\n",
    "        ax2.plot(df_plot[train_mask]['time'], df_plot[train_mask]['mid'], color='red', label='Mid Price (Train)')\n",
    "        ax2.plot(df_plot[~train_mask]['time'], df_plot[~train_mask]['mid'], color='red', linestyle='--', label='Mid Price (Test)')\n",
    "        \n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel(sentiment_col, color='blue')\n",
    "        ax2.set_ylabel('Mid Price', color='red')\n",
    "        \n",
    "        # Adjust y-axis limits for better comparison\n",
    "        y1_min, y1_max = df_plot[sentiment_col].min(), df_plot[sentiment_col].max()\n",
    "        y2_min, y2_max = df_plot['mid'].min(), df_plot['mid'].max()\n",
    "        \n",
    "        y1_range = y1_max - y1_min\n",
    "        y2_range = y2_max - y2_min\n",
    "        \n",
    "        ax1.set_ylim(y1_min - 0.1*y1_range, y1_max + 0.1*y1_range)\n",
    "        ax2.set_ylim(y2_min - 0.1*y2_range, y2_max + 0.1*y2_range)\n",
    "        \n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        plt.title(f'Sentiment vs Mid Price for {self.tag}\\n{sentiment_col}, RT={RT}, T={T}')\n",
    "        \n",
    "        # Combine legends\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        # Format x-axis dates\n",
    "        ax1.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n",
    "        fig.autofmt_xdate()  # Rotate and align the tick labels\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test example\n",
    "if __name__ == \"__main__\":\n",
    "    # ... (previous test code remains the same)\n",
    "\n",
    "    # Run optimization\n",
    "    results = fsa.optimize_parameters(RT_list, model_list, T_list, window_list, keyword_list, train_end_date, n=10)\n",
    "\n",
    "    # Print results\n",
    "    print(results)\n",
    "\n",
    "    # Plot top correlations and time series\n",
    "    fsa.plot_top_correlations(results, n=5, train_end_date=pd.to_datetime(train_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b87358-fcc4-4863-81a8-ade3513f4c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
