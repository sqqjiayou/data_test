{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a833cb-f7a2-4c3f-9d36-7aab539a0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "class ForexSentimentAnalyzer:\n",
    "    def __init__(self, df1: pd.DataFrame, df2: pd.DataFrame, forex_tag: str):\n",
    "        \"\"\"\n",
    "        Initialize the ForexSentimentAnalyzer with input dataframes and forex tag.\n",
    "        \n",
    "        :param df1: DataFrame containing sentiment scores\n",
    "        :param df2: DataFrame containing forex prices\n",
    "        :param forex_tag: String representing the forex pair tag\n",
    "        \"\"\"\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.forex_tag = forex_tag\n",
    "        self.models = [col.split('_')[0] for col in df1.columns if col.endswith('_sentiment_title')]\n",
    "        self.process_df2()\n",
    "\n",
    "    def process_df2(self):\n",
    "        \"\"\"Process df2 to create 'mid' column and handle USD-started forex pairs.\"\"\"\n",
    "        self.df2['mid'] = (self.df2['bid'] + self.df2['ask']) / 2\n",
    "        if self.forex_tag.startswith('USD'):\n",
    "            for col in ['bid', 'ask', 'mid']:\n",
    "                self.df2[col] = 1 / self.df2[col]\n",
    "            self.df2[['bid', 'ask']] = self.df2[['ask', 'bid']]\n",
    "\n",
    "    def resample_df1(self, rt: str, window: int, keyword: str = '') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Resample df1 based on the given parameters.\n",
    "        \n",
    "        :param rt: Resample time period\n",
    "        :param window: Window size for EMA calculation\n",
    "        :param keyword: Keyword to filter df1 (optional)\n",
    "        :return: Resampled DataFrame\n",
    "        \"\"\"\n",
    "        df = self.df1[self.df1['keyword'] == keyword] if keyword else self.df1\n",
    "        df11 = df.set_index('createDate').resample(rt).sum().reset_index()\n",
    "        df11.rename(columns={'createDate': 'time1'}, inplace=True)\n",
    "\n",
    "        for model in self.models:\n",
    "            col = f\"{model}_sentiment_title\"\n",
    "            ema_col = f\"{col}_{window}\"\n",
    "            df11[ema_col] = df11[col].ewm(span=window).mean()\n",
    "\n",
    "        return df11\n",
    "\n",
    "    def resample_df2(self, rt: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Resample df2 based on the given parameters.\n",
    "        \n",
    "        :param rt: Resample time period\n",
    "        :return: Resampled DataFrame\n",
    "        \"\"\"\n",
    "        df21 = self.df2.set_index('asoftime').resample(rt).last().reset_index()\n",
    "        df21.rename(columns={'asoftime': 'time2'}, inplace=True)\n",
    "        return df21\n",
    "\n",
    "    def merge_dataframes(self, df11: pd.DataFrame, df21: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Merge resampled dataframes df11 and df21.\n",
    "        \n",
    "        :param df11: Resampled sentiment DataFrame\n",
    "        :param df21: Resampled forex price DataFrame\n",
    "        :return: Merged DataFrame\n",
    "        \"\"\"\n",
    "        df0 = pd.merge(df11, df21, left_on='time1', right_on='time2', how='outer')\n",
    "        df0['time'] = df0['time1'].combine_first(df0['time2'])\n",
    "        df0.sort_values('time', inplace=True)\n",
    "        df0.reset_index(drop=True, inplace=True)\n",
    "        return df0\n",
    "\n",
    "    def calculate_returns(self, df0: pd.DataFrame, t: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate returns for the given period.\n",
    "        \n",
    "        :param df0: Merged DataFrame\n",
    "        :param t: Number of periods for return calculation\n",
    "        :return: DataFrame with calculated returns\n",
    "        \"\"\"\n",
    "        df0[f'R_{t}'] = df0['mid'].pct_change(t).shift(-t)\n",
    "        return df0\n",
    "\n",
    "    def calculate_correlation(self, df0: pd.DataFrame, model: str, window: int, t: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculate correlation between sentiment scores and returns.\n",
    "        \n",
    "        :param df0: DataFrame with sentiment scores and returns\n",
    "        :param model: Model name\n",
    "        :param window: Window size for EMA calculation\n",
    "        :param t: Number of periods for return calculation\n",
    "        :return: Correlation coefficient\n",
    "        \"\"\"\n",
    "        sentiment_col = f\"{model}_sentiment_title_{window}\"\n",
    "        return_col = f'R_{t}'\n",
    "        return df0[[sentiment_col, return_col]].dropna().corr().iloc[0, 1]\n",
    "\n",
    "    def save_df0(self, df0: pd.DataFrame, rt: str, keyword: str, window: int):\n",
    "        \"\"\"\n",
    "        Save df0 to an Excel file.\n",
    "        \n",
    "        :param df0: DataFrame to save\n",
    "        :param rt: Resample time period\n",
    "        :param keyword: Keyword used for filtering\n",
    "        :param window: Window size for EMA calculation\n",
    "        \"\"\"\n",
    "        filename = f\"records/{self.forex_tag}_{rt}_{keyword}_{window}.xlsx\"\n",
    "        os.makedirs('records', exist_ok=True)\n",
    "        df0.to_excel(filename, index=False)\n",
    "\n",
    "    def load_df0(self, rt: str, keyword: str, window: int) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Load df0 from an Excel file if it exists.\n",
    "        \n",
    "        :param rt: Resample time period\n",
    "        :param keyword: Keyword used for filtering\n",
    "        :param window: Window size for EMA calculation\n",
    "        :return: Loaded DataFrame or None if file doesn't exist\n",
    "        \"\"\"\n",
    "        filename = f\"records/{self.forex_tag}_{rt}_{keyword}_{window}.xlsx\"\n",
    "        if os.path.exists(filename):\n",
    "            return pd.read_excel(filename)\n",
    "        return None\n",
    "\n",
    "    def optimize_parameters(self, rt_list: List[str], keyword_list: List[str], t_list: List[int], \n",
    "                            window_list: List[int], split_date: str, n: int = None) -> List[Tuple[dict, float, float]]:\n",
    "        \"\"\"\n",
    "        Optimize parameters using parallel processing.\n",
    "        \n",
    "        :param rt_list: List of resample time periods\n",
    "        :param keyword_list: List of keywords\n",
    "        :param t_list: List of return periods\n",
    "        :param window_list: List of window sizes\n",
    "        :param split_date: Date to split train and test sets\n",
    "        :param n: Number of top results to return (optional)\n",
    "        :return: List of tuples containing parameters, train correlation, and test correlation\n",
    "        \"\"\"\n",
    "        params_list = list(itertools.product(rt_list, keyword_list, self.models, t_list, window_list))\n",
    "        \n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            results = list(executor.map(self.process_params, params_list, [split_date] * len(params_list)))\n",
    "        \n",
    "        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "        return sorted_results[:n] if n else sorted_results\n",
    "\n",
    "    def process_params(self, params: Tuple[str, str, str, int, int], split_date: str) -> Tuple[dict, float, float]:\n",
    "        \"\"\"\n",
    "        Process a single set of parameters.\n",
    "        \n",
    "        :param params: Tuple containing (rt, keyword, model, t, window)\n",
    "        :param split_date: Date to split train and test sets\n",
    "        :return: Tuple containing parameters dict, train correlation, and test correlation\n",
    "        \"\"\"\n",
    "        rt, keyword, model, t, window = params\n",
    "        df0 = self.load_df0(rt, keyword, window)\n",
    "        \n",
    "        if df0 is None:\n",
    "            df11 = self.resample_df1(rt, window, keyword)\n",
    "            df21 = self.resample_df2(rt)\n",
    "            df0 = self.merge_dataframes(df11, df21)\n",
    "            df0 = self.calculate_returns(df0, t)\n",
    "            self.save_df0(df0, rt, keyword, window)\n",
    "        \n",
    "        train_df = df0[df0['time'] < split_date]\n",
    "        test_df = df0[df0['time'] >= split_date]\n",
    "        \n",
    "        train_corr = self.calculate_correlation(train_df, model, window, t)\n",
    "        test_corr = self.calculate_correlation(test_df, model, window, t)\n",
    "        \n",
    "        return {'rt': rt, 'keyword': keyword, 'model': model, 't': t, 'window': window}, train_corr, test_corr\n",
    "\n",
    "    def plot_top_results(self, results: List[Tuple[dict, float, float]], n: int = 5):\n",
    "        \"\"\"\n",
    "        Plot top n results.\n",
    "        \n",
    "        :param results: List of tuples containing parameters, train correlation, and test correlation\n",
    "        :param n: Number of top results to plot\n",
    "        \"\"\"\n",
    "        top_n = results[:n]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        labels = [f\"{r[0]['model']}\\n{r[0]['rt']}, w={r[0]['window']}, t={r[0]['t']}\" for r in top_n]\n",
    "        train_corrs = [r[1] for r in top_n]\n",
    "        test_corrs = [r[2] for r in top_n]\n",
    "        \n",
    "        x = range(len(top_n))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar([i - width/2 for i in x], train_corrs, width, label='Train')\n",
    "        ax1.bar([i + width/2 for i in x], test_corrs, width, label='Test')\n",
    "        ax1.set_ylabel('Correlation')\n",
    "        ax1.set_title('Top Correlations')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(train_corrs, label='Train', marker='o')\n",
    "        ax2.plot(test_corrs, label='Test', marker='o')\n",
    "        ax2.set_ylabel('Correlation')\n",
    "        ax2.set_title('Correlation Comparison')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# df1 = pd.read_csv('sentiment_scores.csv')\n",
    "# df2 = pd.read_csv('forex_prices.csv')\n",
    "# analyzer = ForexSentimentAnalyzer(df1, df2, 'EURUSD')\n",
    "# results = analyzer.optimize_parameters(\n",
    "#     rt_list=['1H', '4H', '1D'],\n",
    "#     keyword_list=['', 'economy', 'politics'],\n",
    "#     t_list=[1, 3, 5],\n",
    "#     window_list=[5, 10, 20],\n",
    "#     split_date='2023-01-01'\n",
    "# )\n",
    "# for params, train_corr, test_corr in results[:10]:\n",
    "#     print(f\"Parameters: {params}\")\n",
    "#     print(f\"Train correlation: {train_corr:.4f}\")\n",
    "#     print(f\"Test correlation: {test_corr:.4f}\")\n",
    "#     print()\n",
    "# analyzer.plot_top_results(results, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c933b-07d6-4bb2-ae66-8cbf48f1be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Optional\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "class ForexSentimentAnalyzer:\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def load_df0(self, rt: str, keyword: str, window: int, model: str) -> Optional[pd.DataFrame]:\n",
    "        file_path = os.path.join(self.data_dir, f\"df0_{rt}_{keyword}_{window}_{model}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            return pd.read_csv(file_path, parse_dates=['time'])\n",
    "        return None\n",
    "\n",
    "    def save_df0(self, df0: pd.DataFrame, rt: str, keyword: str, window: int, model: str):\n",
    "        file_path = os.path.join(self.data_dir, f\"df0_{rt}_{keyword}_{window}_{model}.csv\")\n",
    "        df0.to_csv(file_path, index=False)\n",
    "\n",
    "    def process_params(self, params: Tuple[str, str, str, int, int], split_date: str) -> Tuple[dict, float, float]:\n",
    "        rt, keyword, model, t, window = params\n",
    "        df0 = self.load_df0(rt, keyword, window, model)\n",
    "        \n",
    "        if df0 is None:\n",
    "            df11 = self.resample_df1(rt, window, keyword)\n",
    "            df21 = self.resample_df2(rt)\n",
    "            df0 = self.merge_dataframes(df11, df21)\n",
    "            df0 = self.calculate_returns(df0, t)\n",
    "            self.save_df0(df0, rt, keyword, window, model)\n",
    "        \n",
    "        df0['time'] = pd.to_datetime(df0['time'])\n",
    "        split_datetime = pd.to_datetime(split_date)\n",
    "        \n",
    "        train_df = df0[df0['time'] < split_datetime]\n",
    "        test_df = df0[df0['time'] >= split_datetime]\n",
    "        \n",
    "        train_corr = self.calculate_correlation(train_df, model, window, t)\n",
    "        test_corr = self.calculate_correlation(test_df, model, window, t)\n",
    "        \n",
    "        return {'rt': rt, 'keyword': keyword, 'model': model, 't': t, 'window': window}, train_corr, test_corr\n",
    "\n",
    "    def calculate_correlation(self, df: pd.DataFrame, model: str, window: int, t: int) -> float:\n",
    "        column_name = f\"{model}_score_ema_{window}\"\n",
    "        returns_column = f\"returns_{t}\"\n",
    "        \n",
    "        # 删除 score 或 returns 列中任何一个为空的行\n",
    "        df_clean = df.dropna(subset=[column_name, returns_column])\n",
    "        \n",
    "        if df_clean.empty:\n",
    "            return 0.0\n",
    "        \n",
    "        correlation = df_clean[column_name].corr(df_clean[returns_column])\n",
    "        return correlation if not np.isnan(correlation) else 0.0\n",
    "\n",
    "    def analyze(self, rt_list: List[str], keyword_list: List[str], model_list: List[str], \n",
    "                t_list: List[int], window_list: List[int], split_date: str, num_workers: int = 4) -> pd.DataFrame:\n",
    "        params_list = [(rt, keyword, model, t, window) \n",
    "                       for rt in rt_list \n",
    "                       for keyword in keyword_list \n",
    "                       for model in model_list \n",
    "                       for t in t_list \n",
    "                       for window in window_list]\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            results = list(executor.map(self.process_params, params_list, [split_date] * len(params_list)))\n",
    "\n",
    "        df_results = pd.DataFrame([\n",
    "            {**params, 'train_corr': train_corr, 'test_corr': test_corr}\n",
    "            for params, train_corr, test_corr in results\n",
    "        ])\n",
    "\n",
    "        # 按照 train_corr 的绝对值从大到小排序\n",
    "        df_results = df_results.sort_values(by='train_corr', key=abs, ascending=False)\n",
    "\n",
    "        return df_results\n",
    "\n",
    "    def plot_top_correlations(self, df_results: pd.DataFrame, top_n: int = 10):\n",
    "        # 使用原始的 train_corr 值进行绘图\n",
    "        top_results = df_results.head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(top_n), top_results['train_corr'], align='center', alpha=0.8, label='Train')\n",
    "        plt.bar(range(top_n), top_results['test_corr'], align='center', alpha=0.6, label='Test')\n",
    "        plt.xlabel('Parameters')\n",
    "        plt.ylabel('Correlation')\n",
    "        plt.title(f'Top {top_n} Correlations')\n",
    "        plt.legend()\n",
    "        plt.xticks(range(top_n), [f\"{row['rt']}-{row['keyword']}-{row['model']}-{row['t']}-{row['window']}\" \n",
    "                                  for _, row in top_results.iterrows()], rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 使用示例\n",
    "analyzer = ForexSentimentAnalyzer('data_directory')\n",
    "results = analyzer.analyze(rt_list, keyword_list, model_list, t_list, window_list, split_date='2024-01-01')\n",
    "print(results)\n",
    "analyzer.plot_top_correlations(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
