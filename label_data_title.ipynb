{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d34f799-0450-4976-bb39-904e4147d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf439a4-7c22-442c-a4ab-5e846aa0128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2024-01-01\"\n",
    "end_date = \"2024-08-30\"\n",
    "folder_path = \"data/fx_new\"\n",
    "#tag = \"GBPUSD\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebd3a0b-a492-499a-b619-cfa16bd77938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Created Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-29 00:50:00+00:00</th>\n",
       "      <td>EUR/USD holds positive ground above 1.0700, eyes on German CPI data</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-29 01:49:00+00:00</th>\n",
       "      <td>GBP/USD holds positive ground above 1.2500 on weaker US Dollar, Fed rate decision looms</td>\n",
       "      <td>GBPUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-29 06:13:00+00:00</th>\n",
       "      <td>EUR/USD Price Analysis: Keeps steady above 1.0700 amid shift to upward momentum</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-29 14:23:00+00:00</th>\n",
       "      <td>USD/JPY finds support near 155.00 after plunging due to probable Japan’s intervention</td>\n",
       "      <td>USDJPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-29 14:33:00+00:00</th>\n",
       "      <td>EUR/USD retreats ahead of Eurozone, US data-packed week</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-26 21:19:00+00:00</th>\n",
       "      <td>USD/JPY Price Forecast: Edges up amid rising US yields, yet remains bearish</td>\n",
       "      <td>USDJPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-26 22:55:00+00:00</th>\n",
       "      <td>GBPUSD slips back below 1.32 on thin Monday volumes</td>\n",
       "      <td>GBPUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-26 23:13:00+00:00</th>\n",
       "      <td>EUR/USD backslides in broad-market Greenback bounce</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 03:39:00+00:00</th>\n",
       "      <td>GBP/USD holds position around 1.3200 ahead of UK PM Starmer’s speech</td>\n",
       "      <td>GBPUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-27 04:36:00+00:00</th>\n",
       "      <td>EUR/USD moves above 1.1150 due to improved market optimism</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             Title  \\\n",
       "Created Date                                                                                                         \n",
       "2024-04-29 00:50:00+00:00                      EUR/USD holds positive ground above 1.0700, eyes on German CPI data   \n",
       "2024-04-29 01:49:00+00:00  GBP/USD holds positive ground above 1.2500 on weaker US Dollar, Fed rate decision looms   \n",
       "2024-04-29 06:13:00+00:00          EUR/USD Price Analysis: Keeps steady above 1.0700 amid shift to upward momentum   \n",
       "2024-04-29 14:23:00+00:00    USD/JPY finds support near 155.00 after plunging due to probable Japan’s intervention   \n",
       "2024-04-29 14:33:00+00:00                                  EUR/USD retreats ahead of Eurozone, US data-packed week   \n",
       "...                                                                                                            ...   \n",
       "2024-08-26 21:19:00+00:00              USD/JPY Price Forecast: Edges up amid rising US yields, yet remains bearish   \n",
       "2024-08-26 22:55:00+00:00                                      GBPUSD slips back below 1.32 on thin Monday volumes   \n",
       "2024-08-26 23:13:00+00:00                                      EUR/USD backslides in broad-market Greenback bounce   \n",
       "2024-08-27 03:39:00+00:00                     GBP/USD holds position around 1.3200 ahead of UK PM Starmer’s speech   \n",
       "2024-08-27 04:36:00+00:00                               EUR/USD moves above 1.1150 due to improved market optimism   \n",
       "\n",
       "                              Tag  \n",
       "Created Date                       \n",
       "2024-04-29 00:50:00+00:00  EURUSD  \n",
       "2024-04-29 01:49:00+00:00  GBPUSD  \n",
       "2024-04-29 06:13:00+00:00  EURUSD  \n",
       "2024-04-29 14:23:00+00:00  USDJPY  \n",
       "2024-04-29 14:33:00+00:00  EURUSD  \n",
       "...                           ...  \n",
       "2024-08-26 21:19:00+00:00  USDJPY  \n",
       "2024-08-26 22:55:00+00:00  GBPUSD  \n",
       "2024-08-26 23:13:00+00:00  EURUSD  \n",
       "2024-08-27 03:39:00+00:00  GBPUSD  \n",
       "2024-08-27 04:36:00+00:00  EURUSD  \n",
       "\n",
       "[992 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = sorted(os.listdir(folder_path))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "#Iterate through each file in the folder\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_excel(file_path)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames from the folder\n",
    "df = pd.concat(data_frames)\n",
    "#drop empty data and some columns\n",
    "df = df.dropna(subset=['Title'])\n",
    "#df = df.drop(columns=['url', 'Content'])\n",
    "#df = df[df['Tag'] == tag]\n",
    "\n",
    "#Set date as index and sort df base on date\n",
    "df.set_index('Created Date', inplace=True)\n",
    "df.index = pd.to_datetime('2024 ' + df.index, format='%Y %b %d, %H:%M %Z')\n",
    "df = df.sort_index()\n",
    "\n",
    "# Filter the DataFrame based on the time period\n",
    "df = df.loc[start_date:end_date]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdd12d-48e0-4709-889d-e548e30d3e44",
   "metadata": {},
   "source": [
    "## InstructABSA\n",
    "Github: https://github.com/kevinscaria/InstructABSA?tab=readme-ov-file Huggingface: https://huggingface.co/kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed20293c-d83c-476e-aeef-7b53fc902f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ABSA model and tokenizerhttps://github.com/kevinscaria/InstructABSA?tab=readme-ov-file\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/instructabsa/tokenizer\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"models/instructabsa/model\")\n",
    "def get_aspect_sentiment(text):\n",
    "    bos_instruction = \"\"\"Definition: \n",
    "        1.The output will be the aspects[\"USD\",\"JPY\",\"GBP\",\"EUR\"] and the aspects sentiment polarity[\"positive\",\"negative\",\"neutral\". \n",
    "        Example: for GBP/USD, the two aspects must be \"GBP\" and \"USD\" \n",
    "        2.This script handle FX data such as GBP/USD, GBP is the base currency, USD is the quote currency, it means to buy GBP and sell USD, so when GBPUSD increase, in general it is more positive for GBP and negative for USD.\n",
    "        3.Since currency pair is in negative relationship, if base currency is positive, quote currency should be neutral or negative, vice versa.\n",
    "        Positive example 1 for base currency-\n",
    "        input: GBP/USD holds positive ground above 1.2500 on weaker US Dollar, Fed's rate decision looms\n",
    "        output: GBP:positive, USD:negative\n",
    "        Positive example 2 for base currency-\n",
    "        input: USD/JPY recovers from 153.60 as US Dollar stabilizes after soft US inflation-induced sell off\n",
    "        output: USD:positive, JPY:neutral\n",
    "        Negative example 1 for base currency-\n",
    "        input: EUR/USD tumbles out of recent range, tests below 1.0770 as markets flee into safe havens\n",
    "        output: EUR:negative, USD:positive\n",
    "        Negative example 2 for base currency-\n",
    "        input: EUR/USD trades with a bearish bias above 1.0750 ahead of US economic data\n",
    "        output: EUR:negative, USD:neutral\n",
    "        Neutral example 1 for both currency-\n",
    "        input: EUR/USD holds positive ground above 1.0700, eyes on German CPI data\n",
    "        output: EUR:neutral, USD:neutral\n",
    "        Neutral example 2 for both currency-\n",
    "        input: GBP/USD Price Analysis: Range bound around 200-DMA, awaiting BoE's decision\n",
    "        output: EUR:neutral, USD:neutral\n",
    "        Now complete the following example-\n",
    "        input: \"\"\"\n",
    "    delim_instruct = ''\n",
    "    eos_instruct = ' \\noutput:'\n",
    "    \n",
    "    tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "    output = model.generate(tokenized_text.input_ids)\n",
    "    print(text, tokenizer.decode(output[0], skip_special_tokens=True).split(\",\"))\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True).split(\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b34cebf3-5889-4167-8239-64b500ee03ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR/USD holds positive ground above 1.0700, eyes on German CPI data ['EUR:positive', ' German CPI data output:positive']\n",
      "GBP/USD holds positive ground above 1.2500 on weaker US Dollar, Fed rate decision looms ['GBP:positive', ' USD:neutral']\n",
      "EUR/USD Price Analysis: Keeps steady above 1.0700 amid shift to upward momentum ['EUR:neutral', ' USD:neutral']\n",
      "USD/JPY finds support near 155.00 after plunging due to probable Japan’s intervention ['USD:negative', ' JPY:negative']\n",
      "EUR/USD retreats ahead of Eurozone, US data-packed week ['EUR:negative', ' Eurozone:negative']\n",
      "GBP/USD Price Analysis: Climbs above 1.2500, with bulls targeting 200-DMA ['GBP:positive', ' USD:positive']\n",
      "EUR/USD finds support near 1.0720 after slow grind on Monday ['EUR:positive', ' USD:neutral']\n",
      "GBP/USD consolidates its gains above 1.2550, investors await Fed rate decision ['GBP:positive', ' Fed rate decision:neutral']\n",
      "EUR/USD Price Analysis: Manages to hold above 200-hour SMA ahead of Eurozone CPI, FOMC ['EUR:positive', ' Eurozone CPI:positive', ' FOMC:positive']\n",
      "USD/JPY recovers as traders buy the dip ['USD:positive', ' JPY:positive']\n",
      "EUR/USD drops on US Dollar's recovery, steady Eurozone inflation ['EUR:negative', ' Eurozone inflation:negative']\n",
      "GBP/USD Price Analysis: Drops below 200-DMA, at cross-roads to resume downtrend ['GBP:negative', ' USD:negative']\n",
      "EUR/USD tumbles out of recent range, tests below 1.0770 as markets flee into safe havens ['EUR:negative', ' USD:negative']\n",
      "GBP/USD holds below 1.2500 ahead of Fed rate decision ['GBP:neutral', ' Fed rate decision:neutral']\n",
      "EUR/USD drops to near 1.0650 ahead of Fed policy ['EUR:negative', ' Fed policy:negative']\n",
      "EUR/USD finds support near 1.0650, downside remains favored ahead of Fed policy ['EUR:positive', ' USD:neutral']\n",
      "GBP/USD Price Analysis: Wavers below 1.2500 as bearish harami looms ['GBP:negative', ' USD:negative']\n",
      "EUR/USD holds mildly up after US data, Fed looms ['EUR:positive', ' USD:neutral']\n",
      "USD/JPY holds losses after Fed decision ['USD:negative', ' Fed decision:negative']\n",
      "GBP/USD fluctuates as Federal Reserve hold rates, plans to slow balance sheet reduction ['GBP:negative', ' Federal Reserve:negative', ' balance sheet reduction:negative']\n",
      "EUR/USD climbs after Fed reaffirms policy outlook, QT taper on the cards ['EUR:positive', ' QT taper on the cards']\n",
      "EUR/USD jitters post-Fed with NFP Friday over the horizon ['EUR:negative', ' NFP Friday:neutral']\n",
      "GBP/USD gains traction above 1.2500, Fed keeps rates steady ['GBP:positive', ' Fed:neutral']\n",
      "EUR/USD remains above 1.0700 amid expectations of Fed refraining from further rate hikes ['EUR:positive', ' USD:neutral']\n",
      "GBP/USD Price Analysis: Advances to near 1.2550 with expectations of a momentum shift ['GBP:positive', ' USD:positive']\n",
      "EUR/USD falls sharply as investors see ECB reducing interest rates before Fed ['EUR:negative', ' ECB:negative', ' interest rates:negative']\n",
      "GBP/USD Price Analysis: Tumbles below crucial 1.2500 as bears move in ['GBP:negative', ' USD:negative']\n",
      "USD/JPY Price Analysis: Drops to a two-week low, at around 153.00 ['USD:negative', ' JPY Price Analysis:negative']\n",
      "EUR/USD recovers to top end of consolidation ahead of Friday’s US NFP ['EUR:positive', ' USD:neutral']\n",
      "GBP/USD trades on a stronger note 1.2530, all eyes on US NFP data ['GBP:positive', ' USD:neutral']\n",
      "EUR/USD advances to near 1.0750 as risk appetite regains balance ['EUR:positive', ' risk appetite:positive']\n",
      "GBP/USD Price Analysis: Moves above 1.2550 to test the channel’s upper boundary ['GBP:positive', ' USD:positive']\n",
      "USD/JPY off the lows after US Dollar bulls came in big ['USD:positive', ' US Dollar bulls came in big']\n",
      "EUR/USD rallies as weak US NFP boosts Fed rate-cut prospects ['EUR:positive', ' US NFP:positive', ' Fed rate-cut prospects']\n",
      "GBP/USD Price Analysis: Bears in charge as ‘shooting star’ looms ['GBP:positive', ' USD:positive']\n",
      "USD/JPY Price Analysis: Bears charge helped by intervention rumors, eye 152.00 ['USD:neutral', ' JPY Price Analysis:negative']\n",
      "EUR/USD breaks above recent congestion as US NFP miss drives down Greenback ['EUR:negative', ' USD:negative']\n",
      "EUR/USD holds positive ground above 1.0750 ahead of Eurozone PMI, PPI data ['EUR:positive', ' Eurozone PMI', ' PPI data output:positive']\n",
      "USD/JPY snaps three-day losing streak above 153.50, Yellen counsels caution on currency intervention ['USD:negative', ' Yellen counsels caution on currency intervention']\n",
      "GBP/USD rises to near 1.2550 due to dovish sentiment surrounding Fed ['GBP:positive', ' USD:positive']\n",
      "USD/JPY inches higher to 153.70 amid a firmer US Dollar ['USD:positive', ' US Dollar:positive']\n",
      "USD/JPY consolidates below 154.00 in Japan’s holiday-truncated week ['USD:positive', ' JPY:positive']\n",
      "EUR/USD advances as US Dollar slips amid firm Fed rate cut bets for September ['EUR:positive', ' US Dollar:negative']\n",
      "GBP/USD Price Analysis: Breaches 200-DMA, buyers eye 1.2600 ['GBP:positive', ' USD:positive']\n",
      "USD/JPY Price Analysis: Climbs toward 154.00 after bouncing off the 50-DMA ['USD:positive', ' JPY:positive']\n",
      "EUR/USD propped up near 1.0750 ahead of European Retail Sales ['EUR:positive', ' European Retail Sales:neutral']\n",
      "GBP/USD extends the rally above 1.2550, eyes on BoE rate decision ['GBP:positive', ' BoE rate decision:neutral']\n",
      "USD/JPY extends recovery above 154.00, focus on Fedspeak ['USD:positive', ' JPY:positive']\n",
      "EUR/USD edges lower to near 1.0750 due to the upward correction in the US Dollar ['EUR:negative', ' USD:negative']\n",
      "USD/JPY rises to near 154.00 amid improved US Dollar ['USD:positive', ' US Dollar:positive']\n",
      "USD/JPY trades higher as USD finds its feet. Intervention still a threat ['USD:positive', ' USD:neutral']\n",
      "EUR/USD recovery stalls as ECB sees three rate cuts this year ['EUR:negative', ' ECB:negative', ' rate cuts:negative']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maspect_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_aspect_sentiment)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[41], line 34\u001b[0m, in \u001b[0;36mget_aspect_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     31\u001b[0m eos_instruct \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124moutput:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m tokenizer(bos_instruction \u001b[38;5;241m+\u001b[39m text \u001b[38;5;241m+\u001b[39m delim_instruct \u001b[38;5;241m+\u001b[39m eos_instruct, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(tokenized_text\u001b[38;5;241m.\u001b[39minput_ids)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(text, tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\generation\\utils.py:1745\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[0;32m   1740\u001b[0m         inputs_tensor, generation_config\u001b[38;5;241m.\u001b[39m_pad_token_tensor, generation_config\u001b[38;5;241m.\u001b[39m_eos_token_tensor\n\u001b[0;32m   1741\u001b[0m     )\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1744\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1746\u001b[0m         inputs_tensor, model_kwargs, model_input_name, generation_config\n\u001b[0;32m   1747\u001b[0m     )\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\generation\\utils.py:549\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[0;32m    547\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    548\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 549\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[0;32m   1093\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         output_attentions,\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m   1107\u001b[0m         hidden_states,\n\u001b[0;32m   1108\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1109\u001b[0m         position_bias\u001b[38;5;241m=\u001b[39mposition_bias,\n\u001b[0;32m   1110\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1111\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1112\u001b[0m         encoder_decoder_position_bias\u001b[38;5;241m=\u001b[39mencoder_decoder_position_bias,\n\u001b[0;32m   1113\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[0;32m   1114\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_layer_head_mask,\n\u001b[0;32m   1115\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[0;32m   1116\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1117\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1118\u001b[0m     )\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:746\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    743\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](hidden_states)\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:335\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    334\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 335\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDenseReluDense(forwarded_states)\n\u001b[0;32m    336\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:303\u001b[0m, in \u001b[0;36mT5DenseGatedActDense.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m--> 303\u001b[0m     hidden_gelu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwi_0(hidden_states))\n\u001b[0;32m    304\u001b[0m     hidden_linear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwi_1(hidden_states)\n\u001b[0;32m    305\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_gelu \u001b[38;5;241m*\u001b[39m hidden_linear\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"aspect_sentiment\"] = df[\"Title\"].apply(get_aspect_sentiment)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56c65128-35f3-4630-99ef-33148607e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fx_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc21265-d48b-4014-a751-f10e5c35b027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
